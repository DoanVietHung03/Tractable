import os
import sys

current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(root_dir)

import config
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from PIL import Image
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor

# --- 1. C·∫§U H√åNH ---
# ƒê∆∞·ªùng d·∫´n ƒë·∫øn Model ƒë√£ train xong (N·∫±m ·ªü root/segformer_house_final)
MODEL_PATH = os.path.join(config.PROJECT_ROOT, "segformer_house_final")

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh Test (N·∫±m ·ªü root/Final_Dataset/test/images)
TEST_DIR = os.path.join(config.PROJECT_ROOT, "Final_Dataset", "test", "images")

NUM_SAMPLES = 10 # S·ªë l∆∞·ª£ng ·∫£nh mu·ªën test th·ª≠

# Map ID sang T√™n (Ph·∫£i kh·ªõp v·ªõi l√∫c train)
id2label = {
    0: "background",
    1: "building",
    2: "window",
    3: "door",
    4: "tree",
    5: "sky",
    6: "road",
    7: "car"
}

# B·∫£ng m√†u hi·ªÉn th·ªã (R, G, B) - T·ª± ch·ªçn m√†u cho d·ªÖ nh√¨n
# 0: ƒêen, 1: ƒê·ªè ƒëun, 2: Xanh d∆∞∆°ng, 3: Cam, 4: Xanh l√°, 5: Xanh tr·ªùi, 6: X√°m, 7: T√≠m
palette = [
    [0, 0, 0],       # 0: background
    [128, 0, 0],     # 1: building
    [0, 0, 128],     # 2: window
    [128, 64, 0],    # 3: door
    [0, 128, 0],     # 4: tree
    [0, 128, 128],   # 5: sky
    [128, 128, 128], # 6: road
    [128, 0, 128]    # 7: car
]

# --- 2. H√ÄM X·ª¨ L√ù ---
def get_device():
    return "cuda" if torch.cuda.is_available() else "cpu"

def colorize_mask(mask, palette):
    """Chuy·ªÉn mask 2D (class ID) th√†nh ·∫£nh m√†u RGB 3D"""
    # mask: (H, W) -> id
    # output: (H, W, 3) -> rgb
    h, w = mask.shape
    color_mask = np.zeros((h, w, 3), dtype=np.uint8)
    
    for label_id, color in enumerate(palette):
        color_mask[mask == label_id] = color
        
    return color_mask

def show_predictions(model, processor, image_paths):
    device = get_device()
    model.to(device)
    model.eval()
    
    for i, img_path in enumerate(image_paths):
        # --- X·ª¨ L√ù ·∫¢NH ---
        image = Image.open(img_path).convert("RGB")
        inputs = processor(images=image, return_tensors="pt").to(device)
        
        with torch.no_grad():
            outputs = model(**inputs)
            
        logits = outputs.logits
        upsampled_logits = torch.nn.functional.interpolate(
            logits,
            size=image.size[::-1],
            mode="bilinear",
            align_corners=False,
        )
        pred_seg = upsampled_logits.argmax(dim=1)[0].cpu().numpy()
        color_pred = colorize_mask(pred_seg, palette)
        
        # --- V·∫º H√åNH (T·∫°o figure ri√™ng cho m·ªói ·∫£nh) ---
        fig, axs = plt.subplots(1, 2, figsize=(14, 6)) # K√≠ch th∆∞·ªõc l·ªõn, d·ªÖ nh√¨n
        
        # ·∫¢nh g·ªëc
        axs[0].imshow(image)
        axs[0].set_title(f"[{i+1}/{len(image_paths)}] ·∫¢nh G·ªëc: {os.path.basename(img_path)}", fontsize=14)
        axs[0].axis('off')
        
        # K·∫øt qu·∫£
        axs[1].imshow(color_pred)
        axs[1].set_title("K·∫øt qu·∫£ Segmentation", fontsize=14)
        axs[1].axis('off')
        
        # Ch√∫ th√≠ch
        patches = [mpatches.Patch(color=np.array(palette[k])/255, label=label) 
                   for k, label in id2label.items()]
        # ƒê·∫∑t ch√∫ th√≠ch b√™n ph·∫£i cho g·ªçn
        fig.legend(handles=patches, loc='center right', title="Ch√∫ gi·∫£i Class")
        
        plt.tight_layout()
        plt.subplots_adjust(right=0.85) # Ch·ª´a ch·ªó cho c√°i Legend b√™n ph·∫£i
        
        print(f"üñºÔ∏è ƒêang hi·ªÉn th·ªã ·∫£nh {i+1}/{len(image_paths)}: {os.path.basename(img_path)}")
        plt.show()

# --- 3. CH·∫†Y TH·ª∞C T·∫æ ---
if __name__ == "__main__":
    print(f"Project Root: {config.PROJECT_ROOT}")
    print(f"Model Path:   {MODEL_PATH}")
    print(f"Test Img Dir: {TEST_DIR}")
    
    if not os.path.exists(MODEL_PATH):
        print("\n‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y folder model!")
        print("üëâ B·∫°n ƒë√£ ch·∫°y xong 'train.py' ch∆∞a?")
        exit()

    if not os.path.exists(TEST_DIR):
        print("\n‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y folder ·∫£nh test!")
        print("üëâ B·∫°n ƒë√£ ch·∫°y 'split_data.py' ƒë·ªÉ t·∫°o dataset ch∆∞a?")
        exit()
        
    try:
        model = SegformerForSemanticSegmentation.from_pretrained(MODEL_PATH)
        processor = SegformerImageProcessor.from_pretrained(MODEL_PATH)
        print("\n‚úÖ ƒê√£ load model th√†nh c√¥ng!")
        
        # L·∫•y ng·∫´u nhi√™n file ·∫£nh
        all_images = [os.path.join(TEST_DIR, f) for f in os.listdir(TEST_DIR) if f.endswith(('.jpg', '.png'))]
        if not all_images:
            print("Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong th∆∞ m·ª•c test!")
        else:
            sample_count = min(len(all_images), NUM_SAMPLES)
            sample_images = np.random.choice(all_images, sample_count, replace=False)
            
            print(f"üì∏ ƒêang d·ª± ƒëo√°n tr√™n {sample_count} ·∫£nh ng·∫´u nhi√™n...")
            show_predictions(model, processor, sample_images)
            print("Xong!")
            
    except Exception as e:
        print(f"L·ªói: {e}")