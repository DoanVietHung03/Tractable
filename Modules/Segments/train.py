import os
import sys
import numpy as np
import torch
from torch.utils.data import Dataset
from PIL import Image
from transformers import (
    SegformerForSemanticSegmentation,
    SegformerImageProcessor,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback,
)
import evaluate

# --- 1. SETUP Äá»‚ IMPORT CONFIG ---
# Láº¥y Ä‘Æ°á»ng dáº«n file hiá»‡n táº¡i, Ä‘i lÃ¹i ra 2 cáº¥p (Modules/Segments -> Root)
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(root_dir)

import config

# --- 2. Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN Tá»° Äá»˜NG ---
# Folder dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº¡o bá»Ÿi split_data.py
FINAL_DATASET_DIR = os.path.join(config.PROJECT_ROOT, "Final_Dataset")
TRAIN_DIR = os.path.join(FINAL_DATASET_DIR, "train")
VAL_DIR = os.path.join(FINAL_DATASET_DIR, "val")

# Folder output (LÆ°u checkpoint vÃ  model final ngay táº¡i thÆ° má»¥c gá»‘c dá»± Ã¡n)
OUTPUT_CHECKPOINT_DIR = os.path.join(config.PROJECT_ROOT, "segformer_house_output")
FINAL_MODEL_DIR = os.path.join(config.PROJECT_ROOT, "segformer_house_final")

# Kiá»ƒm tra an toÃ n trÆ°á»›c khi cháº¡y
if not os.path.exists(TRAIN_DIR):
    print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c Train!")
    print("ğŸ‘‰ Báº¡n Ä‘Ã£ cháº¡y file 'Modules/Preprocess/split_data.py' chÆ°a?")
    exit()

# --- 3. Cáº¤U HÃŒNH CLASS ---
id2label = {
    0: "background",
    1: "building",
    2: "window",
    3: "door",
    4: "tree",
    5: "sky",
    6: "road",
    7: "car"
}
label2id = {v: k for k, v in id2label.items()}
NUM_CLASSES = len(id2label)

MODEL_CHECKPOINT = "nvidia/mit-b1" 

# --- 4. DATASET CLASS ---
class SemanticSegmentationDataset(Dataset):
    def __init__(self, root_dir, processor):
        self.root_dir = root_dir
        self.processor = processor
        self.images_dir = os.path.join(root_dir, "images")
        self.masks_dir = os.path.join(root_dir, "masks")
        
        # Láº¥y danh sÃ¡ch áº£nh, bá» qua file áº©n
        self.images = sorted([f for f in os.listdir(self.images_dir) if not f.startswith('.')])
        self.masks_map = {f: f for f in os.listdir(self.masks_dir)}

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        image_path = os.path.join(self.images_dir, img_name)
        image = Image.open(image_path).convert("RGB")
        
        # Logic tÃ¬m mask thÃ´ng minh
        mask_name = img_name 
        if mask_name not in self.masks_map:
            mask_stem = os.path.splitext(img_name)[0]
            mask_name = mask_stem + ".png"
            
        segmentation_map = Image.open(os.path.join(self.masks_dir, mask_name))

        inputs = self.processor(
            images=image, 
            segmentation_maps=segmentation_map, 
            return_tensors="pt"
        )
        
        inputs = {k: v.squeeze() for k, v in inputs.items()}
        return inputs

# --- 5. CHUáº¨N Bá»Š Dá»® LIá»†U ---
processor = SegformerImageProcessor.from_pretrained(
    MODEL_CHECKPOINT, 
    do_reduce_labels=False
)

train_dataset = SemanticSegmentationDataset(TRAIN_DIR, processor)
val_dataset = SemanticSegmentationDataset(VAL_DIR, processor)

# Kiá»ƒm tra nhanh
print(f"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}")

# --- 6. KHá»I Táº O MODEL ---
model = SegformerForSemanticSegmentation.from_pretrained(
    MODEL_CHECKPOINT,
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True,
)

# --- 7. METRIC (IoU) ---
metric = evaluate.load("mean_iou")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    
    logits_tensor = torch.from_numpy(logits)
    logits_tensor = torch.nn.functional.interpolate(
        logits_tensor,
        size=labels.shape[-2:],
        mode="bilinear",
        align_corners=False,
    ).argmax(dim=1)
    
    pred_labels = logits_tensor.detach().cpu().numpy()
    
    metrics = metric.compute(
        predictions=pred_labels, 
        references=labels, 
        num_labels=NUM_CLASSES, 
        ignore_index=255,
        reduce_labels=False
    )
    
    return {
        "mean_iou": metrics["mean_iou"],
        "mean_accuracy": metrics["mean_accuracy"],
        "overall_accuracy": metrics["overall_accuracy"],
        # An toÃ n hÆ¡n: dÃ¹ng get() Ä‘á»ƒ trÃ¡nh lá»—i index náº¿u dataset thiáº¿u class
        "iou_building": metrics["per_category_iou"][1] if len(metrics["per_category_iou"]) > 1 else 0.0
    }

# --- 8. TRAINING ARGUMENTS ---
training_args = TrainingArguments(
    output_dir=OUTPUT_CHECKPOINT_DIR, # DÃ¹ng Ä‘Æ°á»ng dáº«n tá»« config
    
    learning_rate=6e-5,          
    num_train_epochs=100,        
    lr_scheduler_type="cosine",  # <--- Thay Ä‘á»•i: Giáº£m LR theo hÃ¬nh sin (tá»‘t hÆ¡n linear máº·c Ä‘á»‹nh)
    warmup_ratio=0.1,            # <--- 10% thá»i gian Ä‘áº§u Ä‘á»ƒ "lÃ m nÃ³ng" model, trÃ¡nh shock
    
    # Regularization
    weight_decay=0.01,

    dataloader_num_workers=0, # Chá»‘ng treo mÃ¡y 
    
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4, 
    per_device_eval_batch_size=4,
    
    save_total_limit=2,  # Chá»‰ giá»¯ láº¡i 2 checkpoint gáº§n nháº¥t
    eval_strategy="epoch",
    save_strategy="epoch",
    logging_steps=1,
    remove_unused_columns=False,
    push_to_hub=False,
    
    load_best_model_at_end=True,    # Train xong tá»± Ä‘á»™ng load láº¡i model ngon nháº¥t
    metric_for_best_model="mean_iou", # TiÃªu chÃ­: CÃ¡i nÃ o cÃ³ Mean IoU cao nháº¥t lÃ  NHáº¤T
    greater_is_better=True,
    
    fp16=False,  # DÃ¹ng FP16 náº¿u cÃ³ GPU
)

# --- 9. Báº®T Äáº¦U TRAIN ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=20)],
)

print("\nğŸš€ Báº¯t Ä‘áº§u training tiáº¿p tá»« checkpoint 224...")

checkpoint_path = os.path.join(OUTPUT_CHECKPOINT_DIR, "checkpoint-224")
trainer.train(resume_from_checkpoint=checkpoint_path)

# LÆ°u model cuá»‘i cÃ¹ng vÃ o Ä‘Æ°á»ng dáº«n config
trainer.save_model(FINAL_MODEL_DIR)
processor.save_pretrained(FINAL_MODEL_DIR)
print(f"âœ… Training hoÃ n táº¥t. Model Ä‘Ã£ lÆ°u táº¡i: {FINAL_MODEL_DIR}")