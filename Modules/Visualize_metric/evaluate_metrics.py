import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from tqdm import tqdm
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor
import evaluate

# File n√†y ƒëang ·ªü: Modules/Visualize_metric/evaluate_metrics.py
current_dir = os.path.dirname(os.path.abspath(__file__)) # .../Visualize_metric
parent_dir = os.path.dirname(current_dir)                # .../Modules
root_dir = os.path.dirname(parent_dir)                   # .../Tractable (Root)

# 2. Th√™m root v√†o sys.path ƒë·ªÉ Python nh√¨n th·∫•y to√†n b·ªô d·ª± √°n
sys.path.append(root_dir)

import config

# 3. Import Class t·ª´ file train_segment.py (D√πng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ª´ Root)
try:
    from Modules.Segments.train_segment import SemanticSegmentationDataset, id2label, NUM_CLASSES
except ImportError:
    # Fallback: N·∫øu v·∫´n l·ªói, th·ª≠ import theo c√°ch kh√°c (ph√≤ng tr∆∞·ªùng h·ª£p c·∫•u tr√∫c folder kh√°c)
    print("‚ö†Ô∏è Kh√¥ng import ƒë∆∞·ª£c t·ª´ Modules.Segments. ƒêang th·ª≠ c√°ch kh√°c...")
    sys.path.append(os.path.join(root_dir, "Modules", "Segments"))
    from train_segment import SemanticSegmentationDataset, id2label, NUM_CLASSES

# --- C·∫§U H√åNH ---
MODEL_PATH = os.path.join(config.PROJECT_ROOT, "segformer_house_final")
TEST_DIR = os.path.join(config.PROJECT_ROOT, "Final_Dataset", "test")

def evaluate_model():
    if not os.path.exists(MODEL_PATH):
        print("‚ùå Ch∆∞a c√≥ model final!")
        return

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"‚è≥ ƒêang load model l√™n {device}...")
    
    model = SegformerForSemanticSegmentation.from_pretrained(MODEL_PATH).to(device)
    processor = SegformerImageProcessor.from_pretrained(MODEL_PATH)
    metric = evaluate.load("mean_iou")
    
    # Load t·∫≠p Test
    test_dataset = SemanticSegmentationDataset(TEST_DIR, processor, augment=False)
    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False) # TƒÉng batch n·∫øu GPU m·∫°nh
    
    print("üöÄ ƒêang ch·∫°y ƒë√°nh gi√° tr√™n t·∫≠p Test...")
    model.eval()
    
    for batch in tqdm(test_loader):
        pixel_values = batch["pixel_values"].to(device)
        labels = batch["labels"].to(device)
        
        with torch.no_grad():
            outputs = model(pixel_values=pixel_values)
            
        # Post-process
        logits = outputs.logits
        upsampled_logits = torch.nn.functional.interpolate(
            logits, size=labels.shape[-2:], mode="bilinear", align_corners=False
        )
        predictions = upsampled_logits.argmax(dim=1)
        
        # ƒê·∫©y v√†o metric ƒë·ªÉ t√≠nh to√°n t√≠ch l≈©y
        metric.add_batch(
            predictions=predictions.detach().cpu().numpy(), 
            references=labels.detach().cpu().numpy()
        )
        
    # T√≠nh k·∫øt qu·∫£ cu·ªëi c√πng
    results = metric.compute(num_labels=NUM_CLASSES, ignore_index=255, reduce_labels=False)
    
    print("\nüìä K·∫æT QU·∫¢ FINAL:")
    print(f"Mean IoU: {results['mean_iou']:.4f}")
    print(f"Accuracy: {results['overall_accuracy']:.4f}")
    
    # --- V·∫º BI·ªÇU ƒê·ªí IOU T·ª™NG CLASS ---
    ious = results["per_category_iou"]
    # L·ªçc b·ªè c√°c gi√° tr·ªã NaN (n·∫øu class kh√¥ng xu·∫•t hi·ªán trong t·∫≠p test)
    valid_ious = [x if not np.isnan(x) else 0.0 for x in ious]
    
    class_names = [id2label[i] for i in range(len(valid_ious))]
    
    plt.figure(figsize=(12, 6))
    bars = plt.bar(class_names, valid_ious, color='skyblue')
    
    # T√¥ m√†u ƒë·ªè cho c·ªôt n√†o d∆∞·ªõi 0.5 (Y·∫øu)
    for bar, val in zip(bars, valid_ious):
        if val < 0.5:
            bar.set_color('salmon')
        else:
            bar.set_color('mediumseagreen')
            
        # Hi·ªán s·ªë l√™n ƒë·∫ßu c·ªôt
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
                 f'{val:.2f}', ha='center', va='bottom')

    plt.title(f"IoU t·ª´ng Class (Mean IoU: {results['mean_iou']:.2f})")
    plt.ylabel("IoU Score")
    plt.ylim(0, 1.05)
    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5) # ƒê∆∞·ªùng k·∫ª m·ªëc 0.5
    plt.show()

if __name__ == "__main__":
    evaluate_model()